# The docs: https://www.notion.so/rasa/The-CI-for-model-regression-tests-92af7185e08e4fb2a0c764770a8e9095
name: CI - Model Regression

on:
  schedule:
    # Run once a week
    - cron:  '1 23 * * */7'
  pull_request: # TODO remove later

env:
  GKE_ZONE: us-central1
  GCLOUD_VERSION: "318.0.0"
  GITHUB_ISSUE_LABELS: '["type:bug :bug:", "tool:model-regression-tests"]'

jobs:
  read_test_configuration:
    name: Reads tests configuration
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
    - name: Checkout main
      uses: actions/checkout@v2

    - name: Download yq
      run: |
        curl --location https://github.com/mikefarah/yq/releases/download/3.3.0/yq_linux_amd64 -o yq
        chmod +x yq

    - name: Check if a configuration file exists
      run: test -f .github/configs/mr-test-schedule.yaml

    - name: Set matrix values
      id: set-matrix
      shell: bash
      run: echo "::set-output name=matrix::$(./yq -j r .github/configs/mr-test-schedule.yaml)"

  deploy_runner_gpu:
    name: Deploy Github Runner - GPU
    needs: read_test_configuration
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v2

      - name: Download gomplate
        run: |-
          curl -o gomplate -sSL https://github.com/hairyhenderson/gomplate/releases/download/v3.6.0/gomplate_linux-amd64
          chmod 755 gomplate

      - name: Render deployment template
        run: |-
          export GH_RUNNER_IMAGE=${{ secrets.GH_RUNNER_IMAGE }}
          ./gomplate -f .github/runner/github-runner-deployment.yaml.tmpl -o runner_deployment.yaml

      # Setup gcloud CLI
      - uses: GoogleCloudPlatform/github-actions@e23988b2af9696c66e87d1efbc688d3a80c3be14
        with:
          version: "${{ env.GCLOUD_VERSION }}"
          service_account_key: ${{ secrets.GKE_SA_RASA_CI_CD_GPU_RASA_CI_CD }}
          service_account_email: ${{ secrets.GKE_RASA_CI_GPU_SA_NAME_RASA_CI_CD }}

      # Get the GKE credentials so we can deploy to the cluster
      - run: |-
          gcloud container clusters get-credentials "${{ secrets.GKE_GPU_CLUSTER_RASA_CI_CD }}" --zone "$GKE_ZONE" --project "${{ secrets.GKE_SA_RASA_CI_GPU_PROJECT_RASA_CI_CD }}"

      - name: Deploy Github Runner
        run: |-
          kubectl apply -f runner_deployment.yaml
          kubectl -n github-runner rollout status --timeout=15m deployment/github-runner-$GITHUB_RUN_ID

      - name: Notify slack on failure
        if: failure()
        env:
          SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
        uses: voxmedia/github-action-slack-notify-build@212e9f7a9ca33368c8dd879d6053972128258985
        with:
          channel_id: ${{ secrets.SLACK_ALERTS_CHANNEL_ID }}
          status: FAILED
          color: danger

  model_regression_test_gpu:
    name: Model Regression Tests - GPU
    continue-on-error: true
    needs:
    - deploy_runner_gpu
    - read_test_configuration
    env:
      # Determine where CUDA and Nvidia libraries are located. TensorFlow looks for libraries in the given paths
      LD_LIBRARY_PATH: "/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64"
      ACCELERATOR_TYPE: "GPU"
      GITHUB_ISSUE_TITLE: 'Scheduled Model Regression Test Failed'

    runs-on: [self-hosted, gpu]
    strategy:
      max-parallel: 1
      matrix: ${{fromJson(needs.read_test_configuration.outputs.matrix)}}

    steps:
      - name: Checkout
        uses: actions/checkout@v2

      - name: Checkout dataset
        uses: actions/checkout@v2
        with:
          repository: ${{ secrets.DATASET_REPOSITORY }}
          token: ${{ secrets.ML_TEST_SA_PAT }}
          path: 'dataset'

      - name: Set DATASET and CONFIG variables
        id: set_dataset_config_vars
        env:
          DATASET_NAME: "${{ matrix.dataset }}"
          CONFIG_NAME: "${{ matrix.config }}"
        run: |-
          # determine DATASET and CONFIG environment variables
          source <(gomplate -d mapping=./dataset/dataset_config_mapping.json -f .github/templates/configuration_variables.tmpl)

          # Not all configurations are available for all datasets.
          # The job will fail and the workflow continues, if the configuration file doesn't exist
          # for a given dataset

          echo "::set-output name=is_dataset_exists::true"
          echo "::set-output name=is_config_exists::true"

          test -f dataset/configs/$CONFIG || (echo "::warning::The ${{ matrix.config }} configuration file doesn't exist. Skipping the job." \
            && echo "::set-output name=is_dataset_exists::false" && exit 0)
          test -d dataset/$DATASET || (echo "::warning::The ${{ matrix.dataset }} dataset doesn't exist. Skipping the job." \
            && echo "::set-output name=is_config_exists::false" && exit 0)

          echo "DATASET=${DATASET}" >> $GITHUB_ENV
          echo "CONFIG=${CONFIG}" >> $GITHUB_ENV

      - name: Set up Python 3.8 🐍
        uses: actions/setup-python@v2
        if: steps.set_dataset_config_vars.outputs.is_dataset_exists == 'true' && steps.set_dataset_config_vars.outputs.is_config_exists == 'true'
        with:
          python-version: 3.8

      - name: Read Poetry Version 🔢
        if: steps.set_dataset_config_vars.outputs.is_dataset_exists == 'true' && steps.set_dataset_config_vars.outputs.is_config_exists == 'true'
        run: |
          echo "POETRY_VERSION=$(scripts/poetry-version.sh)" >> $GITHUB_ENV
        shell: bash

      - name: Install poetry 🦄
        uses: Gr1N/setup-poetry@v4
        if: steps.set_dataset_config_vars.outputs.is_dataset_exists == 'true' && steps.set_dataset_config_vars.outputs.is_config_exists == 'true'
        with:
          poetry-version: ${{ env.POETRY_VERSION }}

      - name: Load Poetry Cached Libraries ⬇
        uses: actions/cache@v1
        if: steps.set_dataset_config_vars.outputs.is_dataset_exists == 'true' && steps.set_dataset_config_vars.outputs.is_config_exists == 'true'
        with:
          path: ~/.cache/pypoetry/virtualenvs
          key: ${{ runner.os }}-poetry-${{ env.POETRY_VERSION }}-3.8-${{ hashFiles('**/poetry.lock') }}-${{ secrets.POETRY_CACHE_VERSION }}

      - name: Install Dependencies 📦
        if: steps.set_dataset_config_vars.outputs.is_dataset_exists == 'true' && steps.set_dataset_config_vars.outputs.is_config_exists == 'true'
        run: |
          poetry install --extras full
          make install
          poetry run python -m spacy download de_core_news_md

      - name: Validate that GPUs are working
        if: steps.set_dataset_config_vars.outputs.is_dataset_exists == 'true' && steps.set_dataset_config_vars.outputs.is_config_exists == 'true'
        run: |-
          poetry run python -c 'from tensorflow.python.client import device_lib; print(device_lib.list_local_devices())' || true

      - name: Run test
        id: run_test
        if: steps.set_dataset_config_vars.outputs.is_dataset_exists == 'true' && steps.set_dataset_config_vars.outputs.is_config_exists == 'true'
        env:
          TFHUB_CACHE_DIR: ~/.tfhub_cache/
          OMP_NUM_THREADS: 1
          TF_DETERMINISTIC_OPS: 1 # Run GPUs in a deterministic mode
        run: |-
          poetry run rasa --version

          export NOW_TRAIN=$(gomplate -i '{{ (time.Now).Format time.RFC3339}}');
          cd ${{ github.workspace }}/dataset
          poetry run rasa train nlu --quiet -u $DATASET/train -c configs/$CONFIG --out models/$DATASET/$CONFIG
          echo "::set-output name=train_run_time::$(gomplate -i '{{ $t := time.Parse time.RFC3339 (getenv "NOW_TRAIN") }}{{ (time.Since $t).Round (time.Second 1) }}')"

          export NOW_TEST=$(gomplate -i '{{ (time.Now).Format time.RFC3339}}');
          poetry run rasa test nlu --quiet -u $DATASET/test -m models/$DATASET/$CONFIG --out ${{ github.workspace }}/results/$DATASET/$CONFIG

          echo "::set-output name=test_run_time::$(gomplate -i '{{ $t := time.Parse time.RFC3339 (getenv "NOW_TEST") }}{{ (time.Since $t).Round (time.Second 1) }}')"
          echo "::set-output name=total_run_time::$(gomplate -i '{{ $t := time.Parse time.RFC3339 (getenv "NOW_TRAIN") }}{{ (time.Since $t).Round (time.Second 1) }}')"

      # Download the results of the previous runs
      # The report file is extended with new results every next job run
      - name: Download artifact
        uses: actions/download-artifact@v2
        if: steps.set_dataset_config_vars.outputs.is_dataset_exists == 'true' && steps.set_dataset_config_vars.outputs.is_config_exists == 'true'
        continue-on-error: true
        with:
          name: report.json

      - name: Generate a JSON file with a report / Publish results to Segment
        if: steps.set_dataset_config_vars.outputs.is_dataset_exists == 'true' && steps.set_dataset_config_vars.outputs.is_config_exists == 'true'
        env:
          SUMMARY_FILE: "./report.json"
          SEGMENT_TOKEN: ${{ secrets.SEGMENT_TOKEN }}
          DATASET_NAME: ${{ matrix.dataset }}
          RESULT_DIR: "${{ github.workspace }}/results"
          CONFIG: ${{ matrix.config }}
          TEST_RUN_TIME: ${{ steps.run_test.outputs.test_run_time }}
          TRAIN_RUN_TIME: ${{ steps.run_test.outputs.train_run_time }}
          TOTAL_RUN_TIME: ${{ steps.run_test.outputs.total_run_time }}
          PR_URL: ""
          DATASET_REPOSITORY_BRANCH: "main"
        run: |-
          poetry run pip install analytics-python
          poetry run python .github/scripts/mr_publish_results.py
          poetry run python .github/scripts/mr_generate_summary.py
          cat $SUMMARY_FILE

      - name: Upload an artifact with the report
        if: steps.set_dataset_config_vars.outputs.is_dataset_exists == 'true' && steps.set_dataset_config_vars.outputs.is_config_exists == 'true'
        uses: actions/upload-artifact@v2
        with:
          name: report.json
          path: ./report.json

      - name: Check duplicate issue
        if: failure()
        uses: actions/github-script@v3
        id: issue-exist
        with:
          result-encoding: string
          github-token: ${{ github.token }}
          script: |
            // Get all open issues
            const opts = await github.issues.listForRepo.endpoint.merge({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: ${{ env.GITHUB_ISSUE_LABELS }}
            });
            const issues = await github.paginate(opts)
            // Check if issue exist
            for (const issue of issues) {
              if (issue.title.includes('${{ env.GITHUB_ISSUE_TITLE }}') ) {
                  console.log(`Found an exist issue \#${issue.number}. Skip the following steps.`);
                  return 'true'
                }
            }
            return 'false'

      - name: Select a member from managers team randomly
        if: failure()
        run: |
          # MEMBERS=$(curl \
          #             -H "Authorization: token 58290fcf8a21bec2ce47515a8b5b86c8ce95064e" \
          #             -H "Accept: application/vnd.github.v3+json" \
          #             https://api.github.com/orgs/RasaHQ/teams/research/members)
          # # Make sure we get a list of members
          # [[ -z "$MEMBERS" ]] && echo "Could not find any members from the team." || true

          # # Shuffle the list, then select the first member as the assignee for the issue
          # ASSIGNEE=$(echo $MEMBERS | jq -r '.[].login' | shuf | head -n1)
          # echo ASSIGNEE="$ASSIGNEE" >> $GITHUB_ENV

          echo ASSIGNEE="${{ github.actor }}" >> $GITHUB_ENV # TODO remove later

      - name: Create GitHub Issue 📬
        id: create-issue
        if: failure()
        uses: actions/github-script@v3
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            var issue = await github.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: '${{ env.GITHUB_ISSUE_TITLE }}',
              labels: ${{ env.GITHUB_ISSUE_LABELS }},
              assignees: ['${{ env.ASSIGNEE }}'],
              body: '*This PR is automatically created by the Scheduled Model Regression Test workflow. Checkout the Github Action Run [here](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}).* <br> --- <br> **Description of Problem:** <br> Scheduled Model Regression Test failed. <br> **Configuration**: `${{ matrix.config }}` <br> **Dataset**: `${{ matrix.dataset}}`'
            })
            return issue.data.number

      # - name: Notify Slack of Failure 😱
      #   if: failure()
      #   uses: 8398a7/action-slack@v3
      #   with:
      #     status: custom
      #     fields: workflow,job,commit,repo,ref,author,took
      #     custom_payload: |
      #       {
      #         attachments: [{
      #           fallback: 'fallback',
      #           color: '${{ job.status }}' === 'success' ? 'good' : '${{ job.status }}' === 'failure' ? 'danger' : 'warning',
      #           title: `${process.env.AS_WORKFLOW}`,
      #           text: 'Scheduled model regression test failed :no_entry:️',
      #           fields: [{
      #             title: 'Configuration',
      #             value: '${{ matrix.config }}',
      #             short: false
      #           },
      #           {
      #             title: 'Dataset',
      #             value: '${{ matrix.dataset }}',
      #             short: false
      #           },
      #           {
      #             title: 'GitHub Issue',
      #             value: `https://github.com/${{ github.repository }}/issues/${{ steps.create-issue.outputs.result }}`,
      #             short: false
      #           },
      #           {
      #             title: 'GitHub Action',
      #             value: `https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}`,
      #             short: false
      #           }],
      #           actions: [{
      #           }]
      #         }]
      #       }
      #   env:
      #     SLACK_WEBHOOK_URL: ${{ secrets.SLACK_CI_MODEL_REGRESSION_TEST }}

  analyse_performance:
    name: Analyse Performance
    runs-on: ubuntu-latest
    if: always()
    needs:
    - deploy_runner_gpu
    - model_regression_test_gpu
    env:
      GITHUB_ISSUE_TITLE: 'Scheduled Model Regression Test Performance Drops'

    steps:
      - name: Checkout
        uses: actions/checkout@v2

      - name: Download an artifact with the results for the schedule version
        run: |
          # Get ID of the schedule workflow
          SCHEDULE_ID=$(curl -X GET -s -H 'Authorization: token ${{ secrets.GITHUB_TOKEN }}' -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/workflows" \
            | jq -r  '.workflows[] | select(.name == "${{ github.workflow }}") | select(.path | test("schedule")) | .id')

          ARTIFACT_URL=$(curl -s -H 'Authorization: token ${{ secrets.GITHUB_TOKEN }}'  -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/workflows/${SCHEDULE_ID}/runs?event=schedule&status=completed&branch=main&per_page=1" | jq -r .workflow_runs[0].artifacts_url)

          DOWNLOAD_URL=$(curl -s -H 'Authorization: token ${{ secrets.GITHUB_TOKEN }}' -H "Accept: application/vnd.github.v3+json" "${ARTIFACT_URL}" \
            | jq -r '.artifacts[] | select(.name="report.json") | .archive_download_url')

          # Download the artifact
          curl -H 'Authorization: token ${{ secrets.GITHUB_TOKEN }}' -LJO  -H "Accept: application/vnd.github.v3+json" $DOWNLOAD_URL

          # Unzip and change name
          unzip report.json.zip && mv report.json report_main.json

      - name: Download the report
        uses: actions/download-artifact@v2
        with:
          name: report.json

      - name: Download gomplate
        run: |-
          sudo curl -o /usr/local/bin/gomplate -sSL https://github.com/hairyhenderson/gomplate/releases/download/v3.6.0/gomplate_linux-amd64
          sudo chmod +x /usr/local/bin/gomplate

      - name: Analyse Performance 🔍
        id: performance
        run: |
          OUTPUT="$(gomplate -d data=report.json -d results_main=report_main.json -f .github/templates/model_regression_test_results.tmpl)"

          OUTPUT="${OUTPUT//$'\n'/'%0A'}"
          OUTPUT="${OUTPUT//$'\r'/'%0D'}"
          echo "::set-output name=report_description::${OUTPUT}"

          # TODO remove the fake data later
          OUTPUT='"$OUTPUT | Configuration | Intent Classification Micro F1 | Entity Recognition Micro F1 | Response Selection Micro F1 | |---------------|-----------------|-----------------|-------------------| | `BERT + DIET(bow) + ResponseSelector(bow)`<br> test: `1m30s`, train: `4m16s`, total: `5m45s`|0.7942 (0.06)|0.7529 (0.00)|0.5563 (-0.00)|\n test: `2m46s`, train: `5m5s`, total: `7m51s`|0.8727 (0.00)|0.9113 (0.00)|0.8826 (-0.06)| | `Sparse + DIET(bow) + ResponseSelector(bow)`"'

          # Match all negatives in brackets smaller than -0.05
          # Alert performance drop if found any
          if [[ "${OUTPUT}" =~  \(-[0-9]+.(0[6-9]|[1-9][0-9])\) ]]; then
            echo "Some test performance scores decreased."
            echo "::set-output name=is_dropped::true"
          else
            echo "No test performance drops."
            echo "::set-output name=is_dropped::false"
          fi

      - name: Check duplicate issue
        if: steps.performance.outputs.is_dropped == 'true'
        uses: actions/github-script@v3
        id: issue-exist
        with:
          result-encoding: string
          github-token: ${{ github.token }}
          script: |
            // Get all open issues based on labels
            const opts = await github.issues.listForRepo.endpoint.merge({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: ${{ env.GITHUB_ISSUE_LABELS }}
            });
            const issues = await github.paginate(opts)

            // Check if issue exist by comparing title
            for (const issue of issues) {
              if (issue.title.includes('${{ env.GITHUB_ISSUE_TITLE }}') ) {
                  console.log(`Found an exist issue \#${issue.number}. Skip the following steps.`);
                  return 'true'
                }
            }
            return 'false'

      - name: Select a member from managers team randomly
        if:  steps.performance.outputs.is_dropped == 'true' && steps.issue-exist.outputs.result == 'false'
        run: |
          # MEMBERS=$(curl \
          #             -H "Authorization: token 58290fcf8a21bec2ce47515a8b5b86c8ce95064e" \
          #             -H "Accept: application/vnd.github.v3+json" \
          #             https://api.github.com/orgs/RasaHQ/teams/research/members)
          # # Make sure we get a list of members
          # [[ -z "$MEMBERS" ]] && echo "Could not find any members from the team." || true

          # # Shuffle the list, then select the first member as the assignee for the issue
          # ASSIGNEE=$(echo $MEMBERS | jq -r '.[].login' | shuf | head -n1)
          # echo ASSIGNEE="$ASSIGNEE" >> $GITHUB_ENV

          echo ASSIGNEE="${{ github.actor }}" >> $GITHUB_ENV # TODO remove later

      - name: Create GitHub Issue 📬
        id: create-issue
        if:  steps.performance.outputs.is_dropped == 'true' && steps.issue-exist.outputs.result == 'false'
        uses: actions/github-script@v3
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            var issue = github.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: '${{ env.GITHUB_ISSUE_TITLE }}',
              labels: ${{ env.GITHUB_ISSUE_LABELS }},
              assignees: ['${{ env.ASSIGNEE }}'],
              body: '*This PR is automatically created by the Scheduled Model Regression Test workflow. Checkout the Github Action Run [here](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}).* <br> --- <br> **Description of Problem:** <br>  Some test performance scores **decreased**. Please look at the following table for more details. <br> ${{ steps.performance.outputs.report_description }}'
            })
            return issue.data.number

      # - name: Notify Slack when Performance Drops 💬
      #   if: steps.performance.outputs.is_dropped == 'true'
      #   uses: 8398a7/action-slack@v3
      #   with:
      #     status: custom
      #     fields: workflow,job,commit,repo,ref,author,took
      #     custom_payload: |
      #       {
      #         attachments: [{
      #           fallback: 'fallback',
      #           color: 'danger',
      #           title: `${process.env.AS_WORKFLOW}`,
      #           text: 'Scheduled model regression test performance drops :chart_with_downwards_trend:',
      #           fields: [{
      #             title: 'GitHub Issue',
      #             value: `https://github.com/${{ github.repository }}/issues/${{ steps.create-issue.outputs.result }}`,
      #             short: false
      #           },
      #           {
      #             title: 'GitHub Action',
      #             value: `https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}`,
      #             short: false
      #           }],
      #           actions: [{
      #           }]
      #         }]
      #       }
      #   env:
      #     SLACK_WEBHOOK_URL: ${{ secrets.SLACK_CI_MODEL_REGRESSION_TEST }}

  remove_runner_gpu:
    name: Delete Github Runner - GPU
    if: always()
    needs:
    - deploy_runner_gpu
    - model_regression_test_gpu
    runs-on: ubuntu-latest

    steps:
      # Setup gcloud CLI
      - uses: GoogleCloudPlatform/github-actions@e23988b2af9696c66e87d1efbc688d3a80c3be14
        with:
          version: "${{ env.GCLOUD_VERSION }}"
          service_account_key: ${{ secrets.GKE_SA_RASA_CI_CD_GPU_RASA_CI_CD }}
          service_account_email: ${{ secrets.GKE_RASA_CI_GPU_SA_NAME_RASA_CI_CD }}

      # Get the GKE credentials so we can deploy to the cluster
      - run: |-
          gcloud container clusters get-credentials "${{ secrets.GKE_GPU_CLUSTER_RASA_CI_CD }}" --zone "$GKE_ZONE" --project "${{ secrets.GKE_SA_RASA_CI_GPU_PROJECT_RASA_CI_CD }}"

      - name: Remove Github Runner
        run: kubectl -n github-runner delete deployments github-runner-${GITHUB_RUN_ID} --grace-period=30
